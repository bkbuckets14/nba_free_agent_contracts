{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d5d39cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import sqlite3\n",
    "\n",
    "from name_errors import name_errors_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06995433",
   "metadata": {},
   "source": [
    "## ETL\n",
    "\n",
    "The first step to answering this problem and building a model to predict contract value is to get the data we need. This means that I need data about the players, their stats for different seasons, and the free agents contracts that were signed. To do this, I will perform web scraping on the following webpages to get the needed data.\n",
    "\n",
    "Player Data: https://www.basketball-reference.com/teams/BOS/2021.html \\*Note: Taking data from 'Roster' Table. One webpage/table for each team and year.\n",
    "<br>Stats Data: https://www.basketball-reference.com/leagues/NBA_2021_per_game.html \\*Note: Taking data from 'Player Per Game' Table. One webpage/table for each year.\n",
    "<br>Free Agent Contract Data: https://www.spotrac.com/nba/free-agents/2021/ \\*Note: Taking data from main table. One webpage/table for each year.\n",
    "\n",
    "After the data is scraped, I will add it to a sqlite database. Running this notebook will perform all the necessary steps for webscraping and adding the data to a database.\n",
    "\n",
    "### Web Scraping\n",
    "\n",
    "The first step in the ETL process is scrape three webpages to get player info data, statistics data, and free agent contract data.\n",
    "\n",
    "To start, I will create an array with the years and teams that I am interested in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d1b41af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "YEARS = ['2019', '2020', '2021']\n",
    "\n",
    "TEAMS = ['BOS', 'BRK', 'NYK', 'PHI', 'TOR',\n",
    "         'CLE', 'IND', 'CHI', 'MIL', 'DET',\n",
    "         'MIA', 'CHO', 'ORL', 'ATL', 'WAS',\n",
    "         'NOP', 'DAL', 'SAS', 'MEM', 'HOU',\n",
    "         'DEN', 'MIN', 'UTA', 'OKC', 'POR',\n",
    "         'LAL', 'LAC', 'GSW', 'SAC', 'PHO']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e41dc229",
   "metadata": {},
   "source": [
    "The following function will get the player data for each team for every year. It will also create the player id dictionary that will be used for the statistics data and free agent contract data.\n",
    "\n",
    "Data URL: https://www.basketball-reference.com/teams/BOS/2021.html\n",
    "<br>*Note: Taking data from 'Roster' Table. One webpage/table for each team and year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "be7d5286",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_player_data(years, teams):\n",
    "    #this function will access the player information from each team in teams for each year in years\n",
    "    \n",
    "    player_id_dict = {}\n",
    "    id_count = 1\n",
    "    data = []\n",
    "\n",
    "    for year in years:\n",
    "        for team in teams:\n",
    "            #this section gets the statistics table from Basketball-Reference.com\n",
    "            web = requests.get('https://www.basketball-reference.com/teams/'+team+'/'+year+'.html').text\n",
    "            soup = BeautifulSoup(web, 'lxml')\n",
    "            table = soup.find('tbody').find_all('tr')\n",
    "            \n",
    "            #each row corresponds to one player's information\n",
    "            for row in table:\n",
    "                temp = row.find_all('td')\n",
    "                temp = [x.text for x in temp]\n",
    "                #if a player is already in player_id_dict (previous season or other team), we don't add them again\n",
    "                if temp[0] in player_id_dict:\n",
    "                    continue\n",
    "                player_id_dict[temp[0]] = id_count #generate id for each player\n",
    "                temp[2] = temp[2].split('-')\n",
    "                if temp[6] == 'R': #change rookie to 0 years in league\n",
    "                    temp[6] = '0'\n",
    "                if temp[7] == '': #handles players who didn't go to college\n",
    "                    temp[7] = 'None'\n",
    "                data.append((id_count, temp[0], temp[1], (int(temp[2][0])*12 + int(temp[2][1])), int(temp[3]),\n",
    "                             temp[4], temp[5].upper(), (int(year) - int(temp[6])), temp[7]))\n",
    "                id_count+=1\n",
    "                    \n",
    "    return player_id_dict, data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "253530ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "player_id_dict, player_data = get_player_data(YEARS, TEAMS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6dfa75d",
   "metadata": {},
   "source": [
    "This next cell will get the length of the player_data array and an example tuple from this array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "210fe316",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "756\n",
      "(1, 'Aron Baynes', 'C', 82, 260, 'December 9, 1986', 'NZ', 2013, 'Washington State')\n"
     ]
    }
   ],
   "source": [
    "print(len(player_data))\n",
    "print(player_data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ea98956",
   "metadata": {},
   "source": [
    "The following function will get the statistics data for each year.\n",
    "\n",
    "Data URL: https://www.basketball-reference.com/leagues/NBA_2021_per_game.html\n",
    "<br>*Note: Taking data from 'Player Per Game' Table. One webpage/table for each year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "28e86fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stats_data(years, player_id_dict):\n",
    "    #this function will access the individual stats for the entire NBA for each year in years\n",
    "    \n",
    "    data = [['empty', 'empty', 'empty']]\n",
    "\n",
    "    for year in years:\n",
    "        #this section gets the statistics table from Basketball-Reference.com\n",
    "        web = requests.get('https://www.basketball-reference.com/leagues/NBA_'+year+'_per_game.html').text\n",
    "        soup = BeautifulSoup(web, 'lxml')\n",
    "        table = soup.find('tbody').find_all('tr')\n",
    "        \n",
    "        #each row corresponds to one player's stats\n",
    "        for row in table:\n",
    "            temp = row.find_all('td')\n",
    "            temp = [x.text for x in temp]\n",
    "            \n",
    "            #this if block ignores rows not associated with a player and handles the situation where a player played\n",
    "            #for more than one team in a season.\n",
    "            if temp == [] or temp[0]==data[-1][2]: \n",
    "                continue\n",
    "            temp.pop(1) #get rid of the position\n",
    "            for i in [1, 3, 4]: #set these statistics to integers\n",
    "                temp[i] = int(temp[i])\n",
    "            for i in range(5, len(temp)): #set these statistics to floats\n",
    "                try:\n",
    "                    temp[i] = float(temp[i])\n",
    "                except:\n",
    "                    temp[i] = 0\n",
    "                #try except block handles case where player has undefined percentage stats, sets to 0\n",
    "            \n",
    "            \n",
    "            #gets player_id from player_id_dict, except block handles case where players name is different among pages\n",
    "            try:\n",
    "                p_id = player_id_dict[temp[0]]\n",
    "            except KeyError:\n",
    "                if temp[0] in name_errors_dict:\n",
    "                    p_id = player_id_dict[name_errors_dict[temp[0]]]\n",
    "                if ' '.join(temp[0].split(' ')[:2]) in player_id_dict:\n",
    "                    p_id = player_id_dict[' '.join(temp[0].split(' ')[:2])]\n",
    "                else:\n",
    "                    continue\n",
    "                \n",
    "            temp.insert(0, int(year))\n",
    "            temp.insert(0, p_id)\n",
    "            \n",
    "            \n",
    "            data.append(tuple(temp))\n",
    "    \n",
    "    data.pop(0)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "42d32072",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_data = get_stats_data(YEARS, player_id_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cbc891a",
   "metadata": {},
   "source": [
    "This next cell will get the length of the stats_data array and an example tuple from this array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e7e3870b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1594\n",
      "(425, 2019, '√Ålex Abrines', 25, 'OKC', 31, 2, 19.0, 1.8, 5.1, 0.357, 1.3, 4.1, 0.323, 0.5, 1.0, 0.5, 0.487, 0.4, 0.4, 0.923, 0.2, 1.4, 1.5, 0.6, 0.5, 0.2, 0.5, 1.7, 5.3)\n"
     ]
    }
   ],
   "source": [
    "print(len(stats_data))\n",
    "print(stats_data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8240cf69",
   "metadata": {},
   "source": [
    "The following function will get the free agent contract data for each year.\n",
    "\n",
    "Data URL: https://www.spotrac.com/nba/free-agents/2021/\n",
    "<br>*Note: Taking data from main table. One webpage/table for each year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "104294b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_free_agent_data(years, player_id_dict):\n",
    "    #this function will access the contract information for all the free agents for each year in years\n",
    "    data = []\n",
    "    \n",
    "    for year in years:\n",
    "        #this section gets the statistics table from Spotrac.com\n",
    "        web = requests.get('https://www.spotrac.com/nba/free-agents/'+year+'/').text\n",
    "        soup = BeautifulSoup(web, 'lxml')\n",
    "        table = soup.find('tbody').find_all('tr')\n",
    "        \n",
    "        #each row corresponds to one contract\n",
    "        for row in table:\n",
    "            temp = row.find_all('td')\n",
    "            temp = [x.text.strip() for x in temp]\n",
    "            if temp[7]=='0-': #disregard free agents who didn't sign contracts\n",
    "                continue\n",
    "            temp.pop(1) #get rid of the position\n",
    "            for i in range(len(temp)): #remove extraneous characters\n",
    "                for char in ['$', '>', ',']:\n",
    "                    temp[i] = temp[i].replace(char,'')\n",
    "            temp[1] = float(temp[1])\n",
    "            for i in range(5,8):\n",
    "                temp[i] = int(temp[i])\n",
    "            \n",
    "            #gets player_id from player_id_dict, except block handles case where players name is different among pages\n",
    "            try:\n",
    "                p_id = player_id_dict[temp[0]]\n",
    "            except KeyError:\n",
    "                if temp[0] in name_errors_dict:\n",
    "                    p_id = player_id_dict[name_errors_dict[temp[0]]]\n",
    "                if ' '.join(temp[0].split(' ')[:2]) in player_id_dict:\n",
    "                    p_id = player_id_dict[' '.join(temp[0].split(' ')[:2])]\n",
    "                else:\n",
    "                    continue\n",
    "                \n",
    "            temp.insert(0, int(year))\n",
    "            temp.insert(0, p_id)\n",
    "            \n",
    "            if temp[5]==temp[6]:\n",
    "                change_team = 0\n",
    "            else:\n",
    "                change_team = 1\n",
    "            temp.insert(7, change_team)    \n",
    "            \n",
    "            \n",
    "            data.append(tuple(temp))\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fa3008fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "free_agents_data = get_free_agent_data(YEARS, player_id_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b50613b",
   "metadata": {},
   "source": [
    "This next cell will get the length of the free_agents_data array and an example tuple from this array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8e2acc5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "360\n",
      "(504, 2019, 'Klay Thompson', 29.4, 'UFA', 'GSW', 'GSW', 0, 5, 189903600, 37980720)\n"
     ]
    }
   ],
   "source": [
    "print(len(free_agents_data))\n",
    "print(free_agents_data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a83d6f2",
   "metadata": {},
   "source": [
    "### Loading Data Into Database\n",
    "\n",
    "Now that I have scraped the data we need from the web, I will load this data into a sqlite database. First, I will make sure, that I am starting with a clean slate by removing a past database if it exists and reloading it from the .sql file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "45be63e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm data.db\n",
    "!sqlite3 data.db < data.sql"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce1f85d7",
   "metadata": {},
   "source": [
    "Connecting to the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e8f8a497",
   "metadata": {},
   "outputs": [],
   "source": [
    "con = sqlite3.connect('data.db')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8a06449",
   "metadata": {},
   "source": [
    "Populating the players table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1ac33c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "con.executemany('INSERT INTO players (id, name, position, height, weight, birthday, country, rookie_year, college) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?)', player_data);\n",
    "con.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aec4baa",
   "metadata": {},
   "source": [
    "Checking to make sure the size of the table matches the size of the player_data array from earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "badcc52e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(756,)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(con.execute('SELECT COUNT(*) FROM players'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09c8527b",
   "metadata": {},
   "source": [
    "Populating the stats table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d63eb731",
   "metadata": {},
   "outputs": [],
   "source": [
    "con.executemany('INSERT INTO stats (id, year, name, age, team, games, games_started, minutes, fg, fga, fg_per, three_fg, three_fga, three_fg_per, two_fg, two_fga, two_fg_per, efg_per, ft, fta, ft_per, orb, drb, trb, ast, stl, blk, tov, pfl, pts) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)', stats_data);\n",
    "con.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7b314d4",
   "metadata": {},
   "source": [
    "Checking to make sure the size of the table matches the size of the stats_data array from earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1bfbac37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1594,)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(con.execute('SELECT COUNT(*) FROM stats'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d41e6415",
   "metadata": {},
   "source": [
    "Populating the contracts table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f414ff61",
   "metadata": {},
   "outputs": [],
   "source": [
    "con.executemany('INSERT INTO contracts (id, year, name, age, type, old_team, new_team, chg_team, length, total_dollars, avg_dollars) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)', free_agents_data);\n",
    "con.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b2b0785",
   "metadata": {},
   "source": [
    "Checking to make sure the size of the table matches the size of the free_agents_data array from earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "998a08c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(360,)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(con.execute('SELECT COUNT(*) FROM contracts'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c0ccc696",
   "metadata": {},
   "outputs": [],
   "source": [
    "con.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (en685648)",
   "language": "python",
   "name": "en685648"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
